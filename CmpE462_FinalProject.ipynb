{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CmpE462-FinalProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR7sg0Fp2R8x",
        "colab_type": "text"
      },
      "source": [
        "#Diagnosing Heart Disease from UCI Dataset\n",
        "##Motivation\n",
        "\n",
        "Diagnosing any serious disease will always be a strong motivation for research because health will always be a major interest of humans. Hearth diseases are one of the most common among other diseases and some related attributes are already been collected because of the medical applications nowadays. In this project we propose to diagnose hearth disease based upon the dataset from UCI. The [UCI Dataset](https://www.kaggle.com/ronitf/heart-disease-uci) contains 76 attributes, but all published experiments refer to using a subset of 14 of them. The aim is to determine the presence of heart disease in the patient based upon these attributes. It is integer valued from 0 (no presence) to 4. The dataset will be analyzed and certain Machine Learning models will be estimated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApAfgfUhzZpd",
        "colab_type": "text"
      },
      "source": [
        "## Read The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLjPiEDquYfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sea\n",
        "\n",
        "data=pd.read_csv(\"heart.csv\")\n",
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_1Mt1W33Lgj",
        "colab_type": "text"
      },
      "source": [
        "## Data Analysis\n",
        "### Corrolation Matrix\n",
        "\n",
        "A correlation matrix is a table showing correlation coefficients between sets of variables. Each random variable (Xi) in the table is correlated with each of the other values in the table (Xj). This allows you to see which pairs have the highest correlation.\n",
        "\n",
        "The most corrolated with the classes (target) are:\n",
        "- cp\n",
        "- thalach\n",
        "- exang\n",
        "- oldpeak\n",
        "- slope\n",
        "- ca\n",
        "- thal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KASX5h48uYfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sea.heatmap(data.corr(),annot=True,linewidth=3,);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUSjB5Bv4KgN",
        "colab_type": "text"
      },
      "source": [
        "### Feature Uniqueness\n",
        "Doesn't give much information in our scenario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mom1F8VeuYfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKSf7gW4YWZ",
        "colab_type": "text"
      },
      "source": [
        "##Feature Selection\n",
        "\n",
        "You can drop the fields that you don't want to include by inserting the key into the drop array below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8on16JuYfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split dataset in features and target variable\n",
        "\n",
        "# BEST FEATURES\n",
        "X = data.drop(['target','trestbps','chol','fbs','restecg','age','sex', 'thal'],axis=1) #feature array\n",
        "\n",
        "# BEST FEATURES + THAL\n",
        "# X = data.drop(['target','trestbps','chol','fbs','restecg','age','sex'],axis=1) #feature array\n",
        "\n",
        "# BEST FEATURES + AGE & SEX\n",
        "# X = data.drop(['target','trestbps','chol','fbs','restecg'],axis=1) #feature array\n",
        "\n",
        "# ALL FEATURES\n",
        "# X = data.drop(['target'],axis=1) #feature array\n",
        "\n",
        "\n",
        "y = data.target # response/target\n",
        "\n",
        "print (\"Features Array: \", X.shape)  # metrix\n",
        "print (\"Labels Array: \", y.shape) # series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994_9s7P8L2g",
        "colab_type": "text"
      },
      "source": [
        "##Split\n",
        "\n",
        "Split the 80% of the dataset into training set and 20% to test set so that the model can be trained and tested on different data. Split is done randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-WdASytuYft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Split the dataset into two sets, so that the model can be trained and tested on different data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set (80%)) and test set (20%)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "print (\"Taining data: \", X_train.shape)\n",
        "print (\"Test data: \", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRfVcx-H9HsK",
        "colab_type": "text"
      },
      "source": [
        "##Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMUZifk6uYfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_cm(cm):\n",
        "  '''\n",
        "  Plot the Confusion Matrix.\n",
        "  Yellow-Orange Themed & Count Included & Labeled as TN,FP,FN,TP\n",
        "  '''\n",
        "  plt.clf()\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "  classNames = ['Negative','Positive']\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  tick_marks = np.arange(len(classNames))\n",
        "  plt.xticks(tick_marks, classNames, rotation=45)\n",
        "  plt.yticks(tick_marks, classNames)\n",
        "  s = [['TN','FP'], ['FN','TP']]\n",
        "  for i in range(2):\n",
        "      for j in range(2):\n",
        "          plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
        "  plt.show() \n",
        "  \n",
        "  \n",
        "def plot_cm_orange(cm):\n",
        "  '''\n",
        "  Orange-Brown Themed & Count Included\n",
        "  '''\n",
        "  sea.heatmap(cm,annot=True,cbar=False,cmap=\"Oranges\",fmt=\"d\") \n",
        "  \n",
        "      \n",
        "def plot_cm_purple(cm):\n",
        "  '''\n",
        "  Purple Themed & No Count\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  im = ax.imshow(cm, interpolation='nearest')\n",
        "  ax.figure.colorbar(im, ax=ax)\n",
        "  # We want to show all ticks...\n",
        "  ax.set(xticks=np.arange(cm.shape[1]),\n",
        "         yticks=np.arange(cm.shape[0]),\n",
        "         title='Confusion Matrix for test set',\n",
        "         ylabel='True label',\n",
        "         xlabel='Predicted label')\n",
        "\n",
        "  # Rotate the tick labels and set their alignment.\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "           rotation_mode=\"anchor\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKyT2zGH_5lG",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning Models\n",
        "Analyze the Models seperately and print the Confusion Matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DqCtYjAA4s",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree\n",
        "\n",
        "Apply the Decision Tree algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFbG3KquYfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 1. Create Decision Tree classifer object\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "cf = DecisionTreeClassifier()\n",
        "# Train the model using the training sets\n",
        "cf = cf.fit(X_train,y_train)\n",
        "# make Predictions on the test dataset\n",
        "cf_predicted = cf.predict(X_test)\n",
        "\n",
        "# Classification accuracy, how often is the classifier correct (percentage of correct predictions)?\n",
        "# Determine the accuracy of the model (compare actual value:y_test with predicted value:cf_predicted)\n",
        "print (\"DECISION TREE:\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, cf_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm=metrics.confusion_matrix(y_test, cf_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4K_SHTPAo4d",
        "colab_type": "text"
      },
      "source": [
        "###Generate The Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00kYdm76S_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generate classification tree for DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# Create column list (used by graphviz for ptintin decision tree)\n",
        "# Uncomment the related one with the features selected.\n",
        "\n",
        "\n",
        "# ALL FEATURES INCLUDED\n",
        "# feature_cols = ['age','sex','chest_pain','rest_bp','chol','fasting_bloodsugar','rest_ecg','max_heartrate','excercise_angina','oldpeak','slope','n_major_vasel','thal']\n",
        "\n",
        "\n",
        "# ONLY BEST FEATURES INCLUDED\n",
        "# cp, thalach, exang, oldpeak, slope, ca, thal\n",
        "feature_cols = ['chest_pain','max_heartrate','excercise_angina','oldpeak','slope','n_major_vasel','thal']\n",
        "\n",
        "\n",
        "# ONLY BEST FEATURES INCLUDED\n",
        "# cp, thalach, exang, oldpeak, slope, ca, thal\n",
        "# feature_cols = ['age', 'sex', 'chest_pain','max_heartrate','excercise_angina','oldpeak','slope','n_major_vasel','thal']\n",
        "\n",
        "\n",
        "dot_data = tree.export_graphviz(cf, out_file=None, feature_names=feature_cols,  class_names=['0','1'],  filled=True, rounded=True,  special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "#graph.render(\"class\") ## print pdf file\n",
        "graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czElTAJaA0q0",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression\n",
        "\n",
        "Apply the Logistic Regression algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqhajGKUuYf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 2. Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(solver='liblinear')\n",
        "#Train the model using the training sets\n",
        "lr.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "lr_predicted=lr.predict(X_test)\n",
        "print (\"LOGISTIC REGRESSION:\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, lr_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm=metrics.confusion_matrix(y_test, lr_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WvLiDtdDf_d",
        "colab_type": "text"
      },
      "source": [
        "##Support Vector Machine (SVM)\n",
        "\n",
        "Apply the Support Vector Machine algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OtqhqO2uYf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 3. Support Vector Machine\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "sm = SVC(gamma='auto')\n",
        "#Train the model using the training sets\n",
        "sm.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "#sm.score(X_test, y_test)\n",
        "sm_predicted=sm.predict(X_test)\n",
        "print (\"SUPPORT VECTOR MACHINE\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, sm_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm=metrics.confusion_matrix(y_test, sm_predicted)\n",
        "print(metrics.recall_score(y_test,sm_predicted))\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNdAEiGGDo7S",
        "colab_type": "text"
      },
      "source": [
        "##K-Neighrest Neighbors (kNN)\n",
        "\n",
        "Apply the Support Vector Machine algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyPXDP8VuYf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 4. K-Neighrest Neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "#Train the model using the training sets\n",
        "knn.fit(X_train,y_train)\n",
        "#Predict the response for test dataset\n",
        "knn_predicted = knn.predict(X_test)\n",
        "print (\"K-NEIGHEST NEIGHBORS\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, knn_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm = metrics.confusion_matrix(y_test, knn_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJWP5qpEEMdy",
        "colab_type": "text"
      },
      "source": [
        "##Naive Bayes\n",
        "\n",
        "Apply the Naive Bayes algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMTyXtocvO7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 5. Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gb = GaussianNB()\n",
        "gb.fit(X_train,y_train)\n",
        "gb_predicted = gb.predict(X_test)\n",
        "print (\"NAIVE BAYES\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, gb_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm = metrics.confusion_matrix(y_test, gb_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R77OYwMBERTn",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest\n",
        "\n",
        "Apply the Random Forest algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rRADCravTQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 6. Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "rf_predicted = rf.predict(X_test)\n",
        "print (\"RANDOM FOREST\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, rf_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm = metrics.confusion_matrix(y_test, rf_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5OLITY1EZbH",
        "colab_type": "text"
      },
      "source": [
        "##Neural Network\n",
        "\n",
        "Apply the Neural Network algorithm, show the accuracy and plot the Confusion Matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Udu1NcvX2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model: 7. Neural Network\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "nn = MLPClassifier()\n",
        "nn.fit(X_train,y_train)\n",
        "nn_predicted = nn.predict(X_test)\n",
        "print (\"NEURAL NETWORK\")\n",
        "print (\"Accuracy Score:\")\n",
        "print (metrics.accuracy_score(y_test, nn_predicted))\n",
        "# Compute confusion matrix to evaluate the accuracy of a classification\n",
        "cm = metrics.confusion_matrix(y_test, nn_predicted)\n",
        "\n",
        "plot_cm(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsM4H9ucE0kL",
        "colab_type": "text"
      },
      "source": [
        "#Scoring\n",
        "Run all the Machine Learning Models for 20 times, and give different metrics to score the model results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeurTKBFvljW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A Dictionary of the models to apply.\n",
        "classifier_collection = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression (LibLinear)\": LogisticRegression(solver='liblinear'),\n",
        "    \"Logistic Regression (LBFGS)\": LogisticRegression(solver='lbfgs', max_iter=5000),\n",
        "    \"Logistic Regression (Newton-CG)\": LogisticRegression(solver='newton-cg'),\n",
        "    \"Logistic Regression (SAGA)\": LogisticRegression(solver='saga', max_iter=100000),\n",
        "    \"SVM (Auto)\": SVC(gamma='auto'),\n",
        "    \"SVM (Scale)\": SVC(gamma='scale'),\n",
        "#     \"LinearSVC\": LinearSVC( max_iter=2000000),\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest (10)\": RandomForestClassifier(n_estimators=10),\n",
        "    \"Random Forest (100)\": RandomForestClassifier(n_estimators=100),\n",
        "    \"Neural Network\": MLPClassifier(max_iter=500)\n",
        "}\n",
        "\n",
        "# Create and evaluate models\n",
        "# Evaluation criteria: accuracy_score (help you to choose between models and qualify model performance)\n",
        "\n",
        "all_dict = {}\n",
        "accuracy_score_dict = {}\n",
        "confusion_matrix_dict = {}\n",
        "roc_auc_dict = {}\n",
        "f1_score_dict, precision_dict, recall_dict = {}, {}, {}\n",
        "count=0\n",
        "for classifier_model, classifier in (classifier_collection.items()):\n",
        "    #print(classifier_name)\n",
        "    count +=1\n",
        "    acc_s, roc_auc, f1_s, precision, recall = 0,0,0,0,0\n",
        "    cnt = 20\n",
        "    for _ in range(cnt):\n",
        "      classifier.fit(X_train,y_train)\n",
        "      predicted = classifier.predict(X_test)\n",
        "      acc_s += metrics.accuracy_score(y_test, predicted)\n",
        "      f1_s += metrics.f1_score(y_test, predicted)\n",
        "      precision += metrics.precision_score(y_test, predicted)\n",
        "      recall += metrics.recall_score(y_test, predicted)\n",
        "      roc_auc += metrics.roc_auc_score(y_test, predicted)\n",
        "    \n",
        "    classifier.fit(X_train,y_train)\n",
        "    predicted = classifier.predict(X_test)\n",
        "    print(classifier_model)\n",
        "    print(metrics.classification_report(y_test,predicted))\n",
        "    accuracy_score_dict[classifier_model] = acc_s/cnt\n",
        "    f1_score_dict[classifier_model] = f1_s/cnt\n",
        "    precision_dict[classifier_model] = precision/cnt\n",
        "    recall_dict[classifier_model] = recall/cnt\n",
        "#     confusion_matrix_dict[classifier_model] = {'matrix' : metrics.confusion_matrix(y_test, predicted)}\n",
        "    roc_auc_dict[classifier_model] = roc_auc/cnt\n",
        "    all_dict[classifier_model] = {'accuracy': acc_s/cnt,\n",
        "                                  'f1_score': f1_s/cnt,\n",
        "                                  'precision': precision/cnt,\n",
        "                                  'recall': recall/cnt,\n",
        "                                  'roc_auc': roc_auc/cnt}\n",
        "\n",
        "accuracy_score_dict = [(k, accuracy_score_dict[k]) for k in sorted(accuracy_score_dict, key=accuracy_score_dict.get, reverse=True)]\n",
        "roc_auc_dict = [(k, roc_auc_dict[k]) for k in sorted(roc_auc_dict, key=roc_auc_dict.get, reverse=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJBSi4oXzACR",
        "colab_type": "text"
      },
      "source": [
        "##Different Metrics for models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgDa1-YyKBaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def highlight_max(s):\n",
        "    '''\n",
        "    highlight the maximum in a Series yellow.\n",
        "    '''\n",
        "    is_max = s == s.max()\n",
        "    return ['background-color: limegreen; font-weight: bold;' if v else '' for v in is_max]\n",
        "def custom(s):\n",
        "    return ['text-align: center; padding:5px;' for _ in s]\n",
        "  \n",
        "cm = sea.light_palette(\"green\", as_cmap=True)\n",
        "metrics_df = pd.DataFrame.from_dict(all_dict, orient='index')\n",
        "metrics_df.style.format(\"{:.4}\").apply(highlight_max).apply(custom)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEsjaBqwO6SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}